{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as nn_init\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "import typing as ty\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Tokenizer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_numerical, categories, d_token, bias):\n",
    "        super().__init__()\n",
    "        if categories is None:\n",
    "            d_bias = d_numerical\n",
    "            self.category_offsets = None\n",
    "            self.category_embeddings = None\n",
    "        else:\n",
    "            d_bias = d_numerical + len(categories)\n",
    "            category_offsets = torch.tensor([0] + categories[:-1]).cumsum(0)\n",
    "            self.register_buffer('category_offsets', category_offsets)\n",
    "            self.category_embeddings = nn.Embedding(sum(categories), d_token)\n",
    "            nn_init.kaiming_uniform_(self.category_embeddings.weight, a=math.sqrt(5))\n",
    "            print(f'{self.category_embeddings.weight.shape=}')\n",
    "\n",
    "        # take [CLS] token into account\n",
    "        self.weight = nn.Parameter(Tensor(d_numerical + 1, d_token))\n",
    "        self.bias = nn.Parameter(Tensor(d_bias, d_token)) if bias else None\n",
    "        # The initialization is inspired by nn.Linear\n",
    "        nn_init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            nn_init.kaiming_uniform_(self.bias, a=math.sqrt(5))\n",
    "\n",
    "    @property\n",
    "    def n_tokens(self):\n",
    "        return len(self.weight) + (\n",
    "            0 if self.category_offsets is None else len(self.category_offsets)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "        x_some = x_num if x_cat is None else x_cat\n",
    "        assert x_some is not None\n",
    "        x_num = torch.cat(\n",
    "            [torch.ones(len(x_some), 1, device=x_some.device)]  # [CLS]\n",
    "            + ([] if x_num is None else [x_num]),\n",
    "            dim=1,\n",
    "        )\n",
    "    \n",
    "        x = self.weight[None] * x_num[:, :, None]\n",
    "\n",
    "        if x_cat is not None:\n",
    "            x = torch.cat(\n",
    "                [x, self.category_embeddings(x_cat + self.category_offsets[None])],\n",
    "                dim=1,\n",
    "            )\n",
    "        if self.bias is not None:\n",
    "            bias = torch.cat(\n",
    "                [\n",
    "                    torch.zeros(1, self.bias.shape[1], device=x.device),\n",
    "                    self.bias,\n",
    "                ]\n",
    "            )\n",
    "            x = x + bias[None]\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train = np.load('/mnt/nas/swethamagesh/tabsyn-fresh/tabsyn/data/adult_cond/X_cat_train.npy', allow_pickle=True)\n",
    "num_train = np.load('/mnt/nas/swethamagesh/tabsyn-fresh/tabsyn/data/adult_cond/X_num_train.npy')\n",
    "target = np.load('/mnt/nas/swethamagesh/tabsyn-fresh/tabsyn/data/adult_cond/y_train.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cat_train = np.concatenate([target, cat_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.category_embeddings.weight.shape=torch.Size([50, 4])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(5, [3, 7, 16, 5, 7, 5, 3, 2, 2], 4, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 4, 10, ..., 0, 1, 1],\n",
       "       [0, 4, 9, ..., 0, 0, 1],\n",
       "       [0, 1, 9, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 5, 9, ..., 0, 0, 1],\n",
       "       [0, 4, 10, ..., 0, 0, 1],\n",
       "       [0, 4, 10, ..., 0, 0, 1]], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_cat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  4., 10.,  ...,  0.,  1.,  1.],\n",
       "        [ 0.,  4.,  9.,  ...,  0.,  0.,  1.],\n",
       "        [ 0.,  1.,  9.,  ...,  0.,  0.,  1.],\n",
       "        ...,\n",
       "        [ 0.,  5.,  9.,  ...,  0.,  0.,  1.],\n",
       "        [ 0.,  4., 10.,  ...,  0.,  0.,  1.],\n",
       "        [ 0.,  4., 10.,  ...,  0.,  0.,  1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(final_cat_train.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31062, 15, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_out = tokenizer(torch.from_numpy(num_train), torch.from_numpy(final_cat_train.astype(int)))\n",
    "tokenized_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30k \n",
    "#  get tokenized output\n",
    "# (generate constraint for the entire set at once) - [111100011] - c\n",
    "# constraint for row - 0  & 1 - 0.4  - masked from tokenizd output cxd \n",
    "\n",
    "\n",
    "'''\n",
    "Model load from f'{ckpt_dir}/model.pt'\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vae = torch.load('/mnt/nas/swethamagesh/tabsyn-fresh/tabsyn/tabsyn/vae/ckpt/adult_cond/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE.Tokenizer.weight\n",
      "VAE.Tokenizer.bias\n",
      "VAE.Tokenizer.category_offsets\n",
      "VAE.Tokenizer.category_embeddings.weight\n",
      "VAE.encoder_mu.layers.0.attention.W_q.weight\n",
      "VAE.encoder_mu.layers.0.attention.W_q.bias\n",
      "VAE.encoder_mu.layers.0.attention.W_k.weight\n",
      "VAE.encoder_mu.layers.0.attention.W_k.bias\n",
      "VAE.encoder_mu.layers.0.attention.W_v.weight\n",
      "VAE.encoder_mu.layers.0.attention.W_v.bias\n",
      "VAE.encoder_mu.layers.0.linear0.weight\n",
      "VAE.encoder_mu.layers.0.linear0.bias\n",
      "VAE.encoder_mu.layers.0.linear1.weight\n",
      "VAE.encoder_mu.layers.0.linear1.bias\n",
      "VAE.encoder_mu.layers.0.norm1.weight\n",
      "VAE.encoder_mu.layers.0.norm1.bias\n",
      "VAE.encoder_mu.layers.1.attention.W_q.weight\n",
      "VAE.encoder_mu.layers.1.attention.W_q.bias\n",
      "VAE.encoder_mu.layers.1.attention.W_k.weight\n",
      "VAE.encoder_mu.layers.1.attention.W_k.bias\n",
      "VAE.encoder_mu.layers.1.attention.W_v.weight\n",
      "VAE.encoder_mu.layers.1.attention.W_v.bias\n",
      "VAE.encoder_mu.layers.1.linear0.weight\n",
      "VAE.encoder_mu.layers.1.linear0.bias\n",
      "VAE.encoder_mu.layers.1.linear1.weight\n",
      "VAE.encoder_mu.layers.1.linear1.bias\n",
      "VAE.encoder_mu.layers.1.norm1.weight\n",
      "VAE.encoder_mu.layers.1.norm1.bias\n",
      "VAE.encoder_mu.layers.1.norm0.weight\n",
      "VAE.encoder_mu.layers.1.norm0.bias\n",
      "VAE.encoder_mu.last_normalization.weight\n",
      "VAE.encoder_mu.last_normalization.bias\n",
      "VAE.encoder_mu.head.weight\n",
      "VAE.encoder_mu.head.bias\n",
      "VAE.encoder_logvar.layers.0.attention.W_q.weight\n",
      "VAE.encoder_logvar.layers.0.attention.W_q.bias\n",
      "VAE.encoder_logvar.layers.0.attention.W_k.weight\n",
      "VAE.encoder_logvar.layers.0.attention.W_k.bias\n",
      "VAE.encoder_logvar.layers.0.attention.W_v.weight\n",
      "VAE.encoder_logvar.layers.0.attention.W_v.bias\n",
      "VAE.encoder_logvar.layers.0.linear0.weight\n",
      "VAE.encoder_logvar.layers.0.linear0.bias\n",
      "VAE.encoder_logvar.layers.0.linear1.weight\n",
      "VAE.encoder_logvar.layers.0.linear1.bias\n",
      "VAE.encoder_logvar.layers.0.norm1.weight\n",
      "VAE.encoder_logvar.layers.0.norm1.bias\n",
      "VAE.encoder_logvar.layers.1.attention.W_q.weight\n",
      "VAE.encoder_logvar.layers.1.attention.W_q.bias\n",
      "VAE.encoder_logvar.layers.1.attention.W_k.weight\n",
      "VAE.encoder_logvar.layers.1.attention.W_k.bias\n",
      "VAE.encoder_logvar.layers.1.attention.W_v.weight\n",
      "VAE.encoder_logvar.layers.1.attention.W_v.bias\n",
      "VAE.encoder_logvar.layers.1.linear0.weight\n",
      "VAE.encoder_logvar.layers.1.linear0.bias\n",
      "VAE.encoder_logvar.layers.1.linear1.weight\n",
      "VAE.encoder_logvar.layers.1.linear1.bias\n",
      "VAE.encoder_logvar.layers.1.norm1.weight\n",
      "VAE.encoder_logvar.layers.1.norm1.bias\n",
      "VAE.encoder_logvar.layers.1.norm0.weight\n",
      "VAE.encoder_logvar.layers.1.norm0.bias\n",
      "VAE.encoder_logvar.last_normalization.weight\n",
      "VAE.encoder_logvar.last_normalization.bias\n",
      "VAE.encoder_logvar.head.weight\n",
      "VAE.encoder_logvar.head.bias\n",
      "VAE.decoder.layers.0.attention.W_q.weight\n",
      "VAE.decoder.layers.0.attention.W_q.bias\n",
      "VAE.decoder.layers.0.attention.W_k.weight\n",
      "VAE.decoder.layers.0.attention.W_k.bias\n",
      "VAE.decoder.layers.0.attention.W_v.weight\n",
      "VAE.decoder.layers.0.attention.W_v.bias\n",
      "VAE.decoder.layers.0.linear0.weight\n",
      "VAE.decoder.layers.0.linear0.bias\n",
      "VAE.decoder.layers.0.linear1.weight\n",
      "VAE.decoder.layers.0.linear1.bias\n",
      "VAE.decoder.layers.0.norm1.weight\n",
      "VAE.decoder.layers.0.norm1.bias\n",
      "VAE.decoder.layers.1.attention.W_q.weight\n",
      "VAE.decoder.layers.1.attention.W_q.bias\n",
      "VAE.decoder.layers.1.attention.W_k.weight\n",
      "VAE.decoder.layers.1.attention.W_k.bias\n",
      "VAE.decoder.layers.1.attention.W_v.weight\n",
      "VAE.decoder.layers.1.attention.W_v.bias\n",
      "VAE.decoder.layers.1.linear0.weight\n",
      "VAE.decoder.layers.1.linear0.bias\n",
      "VAE.decoder.layers.1.linear1.weight\n",
      "VAE.decoder.layers.1.linear1.bias\n",
      "VAE.decoder.layers.1.norm1.weight\n",
      "VAE.decoder.layers.1.norm1.bias\n",
      "VAE.decoder.layers.1.norm0.weight\n",
      "VAE.decoder.layers.1.norm0.bias\n",
      "VAE.decoder.last_normalization.weight\n",
      "VAE.decoder.last_normalization.bias\n",
      "VAE.decoder.head.weight\n",
      "VAE.decoder.head.bias\n",
      "Reconstructor.weight\n",
      "Reconstructor.cat_recons.0.weight\n",
      "Reconstructor.cat_recons.0.bias\n",
      "Reconstructor.cat_recons.1.weight\n",
      "Reconstructor.cat_recons.1.bias\n",
      "Reconstructor.cat_recons.2.weight\n",
      "Reconstructor.cat_recons.2.bias\n",
      "Reconstructor.cat_recons.3.weight\n",
      "Reconstructor.cat_recons.3.bias\n",
      "Reconstructor.cat_recons.4.weight\n",
      "Reconstructor.cat_recons.4.bias\n",
      "Reconstructor.cat_recons.5.weight\n",
      "Reconstructor.cat_recons.5.bias\n",
      "Reconstructor.cat_recons.6.weight\n",
      "Reconstructor.cat_recons.6.bias\n",
      "Reconstructor.cat_recons.7.weight\n",
      "Reconstructor.cat_recons.7.bias\n",
      "Reconstructor.cat_recons.8.weight\n",
      "Reconstructor.cat_recons.8.bias\n"
     ]
    }
   ],
   "source": [
    "for i in model_vae.keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'VAE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mmodel_vae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVAE\u001b[49m\u001b[38;5;241m.\u001b[39mTokenizer\u001b[38;5;241m.\u001b[39mstate_dict())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'VAE'"
     ]
    }
   ],
   "source": [
    "tokenizer.load_state_dict(model_vae.'VAE.Tokenizer.state_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umpteenth_attempt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
